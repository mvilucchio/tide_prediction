{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTFeatureExtractor, ViTModel, ViTConfig, DistilBertModel, DistilBertConfig\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "from data_preparation import data_prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PressureEncorder(nn.Module):\n",
    "    def __init__(self, image_size = 41, patch_size = 4, num_channels = 40, encoder_stride = 4):\n",
    "        super(PressureEncorder, self).__init__()\n",
    "        config = ViTConfig(image_size = 41, patch_size = 4, num_channels = 10, encoder_stride = 4)\n",
    "        self.hidden_size = int((image_size // encoder_stride)**2 + 1) * config.hidden_size\n",
    "        self.ViT = ViTModel(config)\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_size + 20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pressure, surge, time = x\n",
    "        time = time.float()\n",
    "        hidden = self.ViT(pressure).last_hidden_state.reshape(-1, self.hidden_size)\n",
    "        x = torch.concat([hidden, surge, time], dim = 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.linspace(1, 0.1, 10)[np.newaxis].to('cuda')\n",
    "\n",
    "def custom_weighted_losses(output, target):\n",
    "    loss = torch.mean(w * (output - target)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data is loaded and scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/X_train_surge_new.npz')\n",
    "Y_train = pd.read_csv('./data/Y_train_surge.csv')\n",
    "X_test = np.load('./data/X_test_surge_new.npz')\n",
    "\n",
    "# train\n",
    "slp_train = X_train['slp']\n",
    "t_slp_train = X_train['t_slp']\n",
    "\n",
    "t_surge1_input_train = X_train['t_surge1_input']\n",
    "t_surge2_input_train = X_train['t_surge2_input']\n",
    "\n",
    "surge1_input_train = X_train['surge1_input']\n",
    "surge2_input_train = X_train['surge2_input']\n",
    "\n",
    "mean_surge1_input_train = np.mean(surge1_input_train, axis=1)\n",
    "std_surge1_input_train = np.std(surge1_input_train, axis=1)\n",
    "mean_surge2_input_train = np.mean(surge2_input_train, axis=1)\n",
    "std_surge2_input_train = np.std(surge2_input_train, axis=1)\n",
    "\n",
    "scaled_surge1_input_train = (surge1_input_train - mean_surge1_input_train[:,None]) / std_surge1_input_train[:,None]\n",
    "scaled_surge2_input_train = (surge2_input_train - mean_surge2_input_train[:,None]) / std_surge2_input_train[:,None]\n",
    "\n",
    "t_surge1_output_train = X_train['t_surge1_output']\n",
    "t_surge2_output_train = X_train['t_surge2_output']\n",
    "\n",
    "# test\n",
    "slp_test = X_test['slp']\n",
    "t_slp_test = X_test['t_slp']\n",
    "\n",
    "t_surge1_input_test = X_test['t_surge1_input']\n",
    "t_surge2_input_test = X_test['t_surge2_input']\n",
    "\n",
    "surge1_input_test = X_test['surge1_input']\n",
    "surge2_input_test = X_test['surge2_input']\n",
    "\n",
    "mean_surge1_input_test = np.mean(surge1_input_test, axis=1)\n",
    "std_surge1_input_test = np.std(surge1_input_test, axis=1)\n",
    "mean_surge2_input_test = np.mean(surge2_input_test, axis=1)\n",
    "std_surge2_input_test = np.std(surge2_input_test, axis=1)\n",
    "\n",
    "scaled_surge1_input_test = (surge1_input_test - mean_surge1_input_test[:,None]) / std_surge1_input_test[:,None]\n",
    "scaled_surge2_input_test = (surge2_input_test - mean_surge2_input_test[:,None]) / std_surge2_input_test[:,None]\n",
    "\n",
    "t_surge1_output_test = X_test['t_surge1_output']\n",
    "t_surge2_output_test = X_test['t_surge2_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to divide the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = Y_train[['surge1_t0', 'surge1_t1', 'surge1_t2', 'surge1_t3', 'surge1_t4', 'surge1_t5', 'surge1_t6', 'surge1_t7', 'surge1_t8', 'surge1_t9']].to_numpy()\n",
    "Y_2 = Y_train[['surge2_t0', 'surge2_t1', 'surge2_t2', 'surge2_t3', 'surge2_t4', 'surge2_t5', 'surge2_t6', 'surge2_t7', 'surge2_t8', 'surge2_t9']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to have a series of pressures the same as the surges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader1, val_dataloader1 = data_prepare(X_train)\n",
    "train_dataloader2, val_dataloader2 = data_prepare(X_train, surge1 = False)\n",
    "test_dataloader1 = data_prepare(X_test, train_set = False)\n",
    "test_dataloader2 = data_prepare(X_test, train_set = False, surge1 = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the transformer to compute the features from the pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "surge_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = PressureEncorder()\n",
    "device = torch.device('cuda')\n",
    "model2 = model2.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b2a0db9d574a1baae3bfb2896c43c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e040090d6aa47238553e30891a38607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Loss = 0.3631873732733678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62675c59d784451fb0342817f33b8141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b4c2c8c6584ba49b60104120f352e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Loss = 0.2739320021828234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a2f77fc4e545f9af9bee52d4551a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3594701a2aac46a49719a530d02c2e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation Loss = 0.2709231238094998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0d626c9c444be8986fdb2c4c8cf648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07445c8c866440ba9fa3e286e595e8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation Loss = 0.2827626325700736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd74cc2c4c864ef9aa0bce555aebd698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALESSA~1\\AppData\\Local\\Temp/ipykernel_15764/207572810.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_weighted_losses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 70\n",
    "batch_size=8\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model2.train()\n",
    "    for x1, x2, x3, y in tqdm(train_dataloader2, total = len(train_dataloader2), leave=False):\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.cuda.FloatTensor)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model2((x1, x2, x3))\n",
    "        loss = custom_weighted_losses(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model2.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        y_preds = []\n",
    "        y_vali = []\n",
    "        #p = 0\n",
    "        for x1, x2, x3, y in tqdm(val_dataloader2, total = len(val_dataloader2), leave = False):\n",
    "            x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "            x1 = x1.type(torch.cuda.FloatTensor)\n",
    "            x2 = x2.type(torch.cuda.FloatTensor)\n",
    "            x3 = x3.type(torch.cuda.FloatTensor)\n",
    "            y = y.type(torch.cuda.FloatTensor)\n",
    "            pred = model2((x1, x2, x3))\n",
    "            #loss = criterion(pred, y)\n",
    "            #val_loss += loss.item()\n",
    "            #p+=1\n",
    "            y_preds.append(pred.to('cpu'))\n",
    "            y_vali.append(y.to('cpu'))\n",
    "\n",
    "    y_pred = []\n",
    "    y_val = []\n",
    "    for j in y_preds:\n",
    "        for i in j:\n",
    "            y_pred.append(i.numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    for j in y_vali:\n",
    "        for i in j:\n",
    "            y_val.append(i.numpy())\n",
    "    y_val = np.array(y_val)\n",
    "        \n",
    "    a=(y_pred-y_val)**2\n",
    "    b = a*np.array([1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1])\n",
    "    val_loss = b.mean()\n",
    "    #val_loss =val_loss/p\n",
    "    print(f'Epoch {epoch+1}: Validation Loss = {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), MODEL_PATH + 'model2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = PressureEncorder()\n",
    "model1.load_state_dict(torch.load(MODEL_PATH + 'model1'))\n",
    "model1.eval()\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdbe1b3818a4c9595969326764f7228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.eval()\n",
    "y_preds = []\n",
    "with torch.no_grad():\n",
    "    for x1, x2, x3 in tqdm(test_dataloader1, total = len(test_dataloader1), leave = False):\n",
    "        x1, x2, x3 = x1.to(device), x2.to(device), x3.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        pred = model1((x1, x2, x3))\n",
    "        y_preds.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55f9dea9fc3431f96004622069a7100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.eval()\n",
    "y_preds = []\n",
    "y_vali = []\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for x1, x2, x3, y in tqdm(val_dataloader1, total = len(val_dataloader1), leave = False):\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.cuda.FloatTensor)\n",
    "        pred = model1((x1, x2, x3))\n",
    "        y_preds.append(pred.to('cpu'))\n",
    "        y_vali.append(y.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_val = []\n",
    "\n",
    "for j in y_preds:\n",
    "    for i in j:\n",
    "        y_pred.append(i.numpy())\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "for j in y_vali:\n",
    "    for i in j:\n",
    "        y_val.append(i.numpy())\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=(y_pred-y_val)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a*np.array([1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38195821640475774"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surge_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = PressureEncorder()\n",
    "device = torch.device('cuda')\n",
    "model2 = model2.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 8\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model2.train()\n",
    "    for x1, x2, x3, y in tqdm(train_dataloader2, total = len(train_dataloader2), leave=False):\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.cuda.FloatTensor)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model2((x1, x2, x3))\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model2.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, x3, y in tqdm(val_dataloader2, total = len(val_dataloader2), leave = False):\n",
    "            x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "            x1 = x1.type(torch.cuda.FloatTensor)\n",
    "            x2 = x2.type(torch.cuda.FloatTensor)\n",
    "            x3 = x3.type(torch.cuda.FloatTensor)\n",
    "            y = y.type(torch.cuda.FloatTensor)\n",
    "            pred = model2((x1, x2, x3))\n",
    "            loss = criterion(pred, y)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= (len(val_dataloader2)*batch_size)\n",
    "    print(f'Epoch {epoch+1}: Validation Loss = {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), MODEL_PATH + 'model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.load(MODEL_PATH + 'model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALESSA~1\\AppData\\Local\\Temp/ipykernel_12628/163729991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "model1.eval(test_dataloader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1d83f4d4fbbec24dd5335a3ea8411cfa594cd5b986a6b3006b93e5d6545557f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mallatproj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
