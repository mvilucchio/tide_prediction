{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTFeatureExtractor, ViTModel, ViTConfig, DistilBertModel, DistilBertConfig\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "from data_preparation import fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PressureEncorder(nn.Module):\n",
    "    def __init__(self, image_size = 41, patch_size = 4, num_channels = 40, encoder_stride = 4):\n",
    "        super(PressureEncorder, self).__init__()\n",
    "        config = ViTConfig(image_size = 41, patch_size = 4, num_channels = 10, encoder_stride = 4)\n",
    "        self.hidden_size = int((image_size // encoder_stride)**2 + 1) * config.hidden_size\n",
    "        self.ViT = ViTModel(config)\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_size + 20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pressure, surge, time = x\n",
    "        time = time.float()\n",
    "        hidden = self.ViT(pressure).last_hidden_state.reshape(-1, self.hidden_size)\n",
    "        x = torch.concat([hidden, surge, time], dim = 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num classes : numer of output parameters\n",
    "class LSTMSurge(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, more_hidden_size=10, final_values=10):\n",
    "        super(LSTMSurge, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        layers = [\n",
    "            nn.Linear(hidden_size, more_hidden_size), \n",
    "            nn.GELU(), \n",
    "            nn.Linear(more_hidden_size, final_values)\n",
    "        ]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(\n",
    "            torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        )\n",
    "        \n",
    "        c_0 = Variable(\n",
    "            torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        )\n",
    "        \n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.mlp(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.linspace(1, 0.1, 10)[np.newaxis]\n",
    "\n",
    "def custom_weighted_losses(output, target):\n",
    "    loss = torch.mean(w * (output - target)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data is loaded and scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/X_train_surge.npz')\n",
    "Y_train = pd.read_csv('./data/Y_train_surge.csv')\n",
    "X_test = np.load('./data/X_test_surge.npz')\n",
    "\n",
    "# train\n",
    "slp_train = X_train['slp']\n",
    "t_slp_train = X_train['t_slp']\n",
    "\n",
    "t_surge1_input_train = X_train['t_surge1_input']\n",
    "t_surge2_input_train = X_train['t_surge2_input']\n",
    "\n",
    "surge1_input_train = X_train['surge1_input']\n",
    "surge2_input_train = X_train['surge2_input']\n",
    "\n",
    "mean_surge1_input_train = np.mean(surge1_input_train, axis=1)\n",
    "std_surge1_input_train = np.std(surge1_input_train, axis=1)\n",
    "mean_surge2_input_train = np.mean(surge2_input_train, axis=1)\n",
    "std_surge2_input_train = np.std(surge2_input_train, axis=1)\n",
    "\n",
    "scaled_surge1_input_train = (surge1_input_train - mean_surge1_input_train[:,None]) / std_surge1_input_train[:,None]\n",
    "scaled_surge2_input_train = (surge2_input_train - mean_surge2_input_train[:,None]) / std_surge2_input_train[:,None]\n",
    "\n",
    "t_surge1_output_train = X_train['t_surge1_output']\n",
    "t_surge2_output_train = X_train['t_surge2_output']\n",
    "\n",
    "# test\n",
    "slp_test = X_test['slp']\n",
    "t_slp_test = X_test['t_slp']\n",
    "\n",
    "t_surge1_input_test = X_test['t_surge1_input']\n",
    "t_surge2_input_test = X_test['t_surge2_input']\n",
    "\n",
    "surge1_input_test = X_test['surge1_input']\n",
    "surge2_input_test = X_test['surge2_input']\n",
    "\n",
    "mean_surge1_input_test = np.mean(surge1_input_test, axis=1)\n",
    "std_surge1_input_test = np.std(surge1_input_test, axis=1)\n",
    "mean_surge2_input_test = np.mean(surge2_input_test, axis=1)\n",
    "std_surge2_input_test = np.std(surge2_input_test, axis=1)\n",
    "\n",
    "scaled_surge1_input_test = (surge1_input_test - mean_surge1_input_test[:,None]) / std_surge1_input_test[:,None]\n",
    "scaled_surge2_input_test = (surge2_input_test - mean_surge2_input_test[:,None]) / std_surge2_input_test[:,None]\n",
    "\n",
    "t_surge1_output_test = X_test['t_surge1_output']\n",
    "t_surge2_output_test = X_test['t_surge2_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to divide the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = Y_train[['surge1_t0', 'surge1_t1', 'surge1_t2', 'surge1_t3', 'surge1_t4', 'surge1_t5', 'surge1_t6', 'surge1_t7', 'surge1_t8', 'surge1_t9']].to_numpy()\n",
    "Y_2 = Y_train[['surge2_t0', 'surge2_t1', 'surge2_t2', 'surge2_t3', 'surge2_t4', 'surge2_t5', 'surge2_t6', 'surge2_t7', 'surge2_t8', 'surge2_t9']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to have a series of pressures the same as the surges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressures_same_time_1 = np.empty((*(t_surge1_input_train.shape), 41, 41))\n",
    "for i, time_series in enumerate(t_surge1_input_train):\n",
    "    for j, time in enumerate(time_series):\n",
    "        idx = find_nearest(t_slp_train[i,:].flatten(), time)\n",
    "        pressures_same_time_1[i, j, :, :] = slp_train[i, idx, :, :]\n",
    "\n",
    "pressures_same_time_2 = np.empty((*(t_surge2_input_train.shape), 41, 41))\n",
    "for i, time_series in enumerate(t_surge2_input_train):\n",
    "    for j, time in enumerate(time_series):\n",
    "        idx = find_nearest(t_slp_train[i,:].flatten(), time)\n",
    "        pressures_same_time_2[i, j, :, :] = slp_train[i, idx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pressures_same_time_1 = np.mean(pressures_same_time_1, axis=(1,2,3))\n",
    "std_pressures_same_time_1 = np.std(pressures_same_time_1, axis=(1,2,3))\n",
    "mean_pressures_same_time_2 = np.mean(pressures_same_time_2, axis=(1,2,3))\n",
    "std_pressures_same_time_2 = np.std(pressures_same_time_2, axis=(1,2,3))\n",
    "\n",
    "scaled_pressures_same_time_1 = (pressures_same_time_1 - mean_pressures_same_time_1[:,None, None, None]) / std_pressures_same_time_1[:,None, None, None]\n",
    "scaled_pressures_same_time_2 = (pressures_same_time_2 - mean_pressures_same_time_2[:,None, None, None]) / std_pressures_same_time_2[:,None, None, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_rounder(t):\n",
    "    return (t.replace(second=0, microsecond=0, minute=0, hour=t.hour) + timedelta(hours=t.minute//30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_hour(array):\n",
    "    hours_array = np.empty_like(array)\n",
    "    for i, times in enumerate(array):\n",
    "        for j, t in enumerate(times):\n",
    "            if t<0:\n",
    "                tt = (datetime(1970,1,1) + timedelta(seconds=int(t))).timetuple()\n",
    "            else:\n",
    "                tt = (datetime.fromtimestamp(int(t))).timetuple() \n",
    "            hours_array[i][j] = tt.tm_yday * 24 + tt.tm_hour\n",
    "    return hours_array / (366 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_in_year_surge_1_train = time_to_hour(t_surge1_input_train)\n",
    "hours_in_year_surge_2_train = time_to_hour(t_surge2_input_train)\n",
    "hours_in_year_surge_1_test = time_to_hour(t_surge1_input_test)\n",
    "hours_in_year_surge_2_test = time_to_hour(t_surge1_input_test)\n",
    "hours_in_year_surge_1_output_train = time_to_hour(t_surge1_output_train)\n",
    "hours_in_year_surge_2_output_train = time_to_hour(t_surge2_output_train)\n",
    "hours_in_year_slp_train = time_to_hour(t_slp_train)\n",
    "hours_in_year_slp_test = time_to_hour(t_slp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = len(surge1_input_train)\n",
    "trainlen = int(0.9 * datalen)\n",
    "vallen = datalen - trainlen\n",
    "train_idx, val_idx = torch.utils.data.random_split(np.arange(datalen), [trainlen, vallen])\n",
    "\n",
    "pressure1_train, pressure1_val = pressures_same_time_1[train_idx], pressures_same_time_1[val_idx]\n",
    "surge1_train, surge1_val = surge1_input_train[train_idx], surge1_input_train[val_idx]\n",
    "t_surge1_train, t_surge1_val = hours_in_year_surge_1_train[train_idx], hours_in_year_surge_1_train[val_idx]\n",
    "Y_1_train, Y_1_val = Y_1[train_idx], Y_1[val_idx]\n",
    "\n",
    "train_data = list(zip(pressure1_train, surge1_train, t_surge1_train, Y_1_train))\n",
    "val_data = list(zip(pressure1_val, surge1_val, t_surge1_val, Y_1_val))\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader1 = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader1 = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = len(surge2_input_train)\n",
    "trainlen = int(0.9 * datalen)\n",
    "vallen = datalen - trainlen\n",
    "train_idx, val_idx = torch.utils.data.random_split(np.arange(datalen), [trainlen, vallen])\n",
    "\n",
    "pressure2_train, pressure2_val = pressures_same_time_2[train_idx], pressures_same_time_2[val_idx]\n",
    "surge2_train, surge2_val = surge2_input_train[train_idx], surge2_input_train[val_idx]\n",
    "t_surge2_train, t_surge2_val = hours_in_year_surge_2_train[train_idx], hours_in_year_surge_2_train[val_idx]\n",
    "Y_2_train, Y_2_val = Y_2[train_idx], Y_2[val_idx]\n",
    "\n",
    "train_data = list(zip(pressure2_train, surge2_train, t_surge2_train, Y_2_train))\n",
    "val_data = list(zip(pressure2_val, surge2_val, t_surge2_val, Y_2_val))\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader2 = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader2 = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the transformer to compute the features from the pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PressureEncorder()\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = PressureEncorder()\n",
    "device = torch.device('cuda')\n",
    "model2 = model2.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8207e6dc79cf4b3aaa43d04adc8870ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2788dd2798904642a7766ec727740379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Loss = 0.1288423269454922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcc457b59784acc8e38f37621041269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a048ada505c746abb25452005c7d4d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Loss = 0.1096935369606529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03472a661d144b08103d5de424546eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de12b317beca44b6bc3885345caab9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation Loss = 0.10331852491945029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e10fa191b5a403297ce599b34813009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8157735f6bb64362a1b0ec99dbd426f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation Loss = 0.1031464260071516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f6df09fe1240239458eaf0d2d30d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aceeba9a917e436494fdff5ab1d08e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validation Loss = 0.09250378598059927\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506ce2a509ee4e4abdff71f029079124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9507bcaa324330a04c9ca39304a0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Validation Loss = 0.09212010164878198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3bab95a38e4bc9a8d352d1e23e2777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9e044567f44d9680328515dfa4e641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Validation Loss = 0.09121082316019706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c063ea9b7d304fb99a90d2087bb60eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfeef02d1ee4409886cbaadbccc2821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Validation Loss = 0.08871275082762753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbc229ee20a44ddaccb8be1a58682d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92b720999be40a4a04aa7e76a6b955f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Validation Loss = 0.09629658527140106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a1c6479b644f5288ed8435155c6591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776a1a4f80f142a38143275fb7471402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Validation Loss = 0.09216671303978988\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for x1, x2, x3, y in tqdm(train_dataloader1, total = len(train_dataloader1), leave=False):\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.cuda.FloatTensor)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model((x1, x2, x3))\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, x3, y in tqdm(val_dataloader1, total = len(val_dataloader1), leave = False):\n",
    "            x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "            x1 = x1.type(torch.cuda.FloatTensor)\n",
    "            x2 = x2.type(torch.cuda.FloatTensor)\n",
    "            x3 = x3.type(torch.cuda.FloatTensor)\n",
    "            y = y.type(torch.cuda.FloatTensor)\n",
    "            pred = model((x1, x2, x3))\n",
    "            loss = criterion(pred, y)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= (len(val_dataloader1)*batch_size)\n",
    "    print(f'Epoch {epoch+1}: Validation Loss = {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH + 'model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model = torch.load(MODEL_PATH + 'model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in the_model:\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6164e43c42554713a796fdcd87853181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dfbc163aa0402782c819b47263aae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Loss = 0.135145779805524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2e8a93b81145aa84b8a726aaa0ee09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed024e4efef472b9dc20c74c64bb021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Loss = 0.09165589005819388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b658be79a52f4b98be01388db357d593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949d532fd48c46bda845197ef061e29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation Loss = 0.07321264786379678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6041d72caa4103b1b19729195f07eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0a58e58bfe471a8e07bac1c819101e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation Loss = 0.07516622210719756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e73efd8e7954771af98f79fa23be4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8228f0ab50442aa81427872c4e0610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validation Loss = 0.06908614127231495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397b27cb35c64506905e291f5c1565ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750cc558b1a14ce69bc2f55c85d6de63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Validation Loss = 0.06613935993186065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf2f00577eb40fe8c8c6ff4af623d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f488a27a2140aa86dfcf1375d25ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Validation Loss = 0.07580856989536966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9376aefaf77f473ab341e5c1fb1dac8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fc7fc809ee497f98642ad3690c50ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Validation Loss = 0.06630034715469395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cd27780d6147478528669df3f4a565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd87eeaab178450b83d3de1c7aa53828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Validation Loss = 0.0630223360178726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcbf14f5198412c8cc8d50f69360cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b18dbfae90540d6aee1f720e9905de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Validation Loss = 0.06640488284506968\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model2.train()\n",
    "    for x1, x2, x3, y in tqdm(train_dataloader2, total = len(train_dataloader2), leave=False):\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.cuda.FloatTensor)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model2((x1, x2, x3))\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model2.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, x3, y in tqdm(val_dataloader2, total = len(val_dataloader2), leave = False):\n",
    "            x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "            x1 = x1.type(torch.cuda.FloatTensor)\n",
    "            x2 = x2.type(torch.cuda.FloatTensor)\n",
    "            x3 = x3.type(torch.cuda.FloatTensor)\n",
    "            y = y.type(torch.cuda.FloatTensor)\n",
    "            pred = model2((x1, x2, x3))\n",
    "            loss = criterion(pred, y)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= (len(val_dataloader2)*batch_size)\n",
    "    print(f'Epoch {epoch+1}: Validation Loss = {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), MODEL_PATH + 'model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "lstm = LSTMSurge(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, trainY)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1d83f4d4fbbec24dd5335a3ea8411cfa594cd5b986a6b3006b93e5d6545557f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mallatproj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
