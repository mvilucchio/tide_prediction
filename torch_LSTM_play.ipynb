{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTFeatureExtractor, ViTModel, ViTConfig, DistilBertModel, DistilBertConfig\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "from data_preparation_play import data_prepare_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PressureEncorder(nn.Module):\n",
    "    def __init__(self, image_size = 41, patch_size = 4, num_channels = 40, encoder_stride = 4):\n",
    "        super(PressureEncorder, self).__init__()\n",
    "        config = ViTConfig(image_size = 41, patch_size = 4, num_channels = 20, encoder_stride = 4)\n",
    "        self.hidden_size = int((image_size // encoder_stride)**2 + 1) * config.hidden_size\n",
    "        self.ViT = ViTModel(config)\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_size + 20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pressure, surge, time = x\n",
    "        time = time.float()\n",
    "        hidden = self.ViT(pressure).last_hidden_state.reshape(-1, self.hidden_size)\n",
    "        x = torch.concat([hidden, surge, time], dim = 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.linspace(1, 0.1, 10)[np.newaxis].to('cuda')\n",
    "\n",
    "def custom_weighted_losses(output, target):\n",
    "    loss = torch.mean(w * (output - target)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data is loaded and scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/X_train_surge_new.npz')\n",
    "Y_train = pd.read_csv('./data/Y_train_surge.csv')\n",
    "X_test = np.load('./data/X_test_surge_new.npz')\n",
    "\n",
    "# train\n",
    "slp_train = X_train['slp']\n",
    "t_slp_train = X_train['t_slp']\n",
    "\n",
    "t_surge1_input_train = X_train['t_surge1_input']\n",
    "t_surge2_input_train = X_train['t_surge2_input']\n",
    "\n",
    "surge1_input_train = X_train['surge1_input']\n",
    "surge2_input_train = X_train['surge2_input']\n",
    "\n",
    "mean_surge1_input_train = np.mean(surge1_input_train, axis=1)\n",
    "std_surge1_input_train = np.std(surge1_input_train, axis=1)\n",
    "mean_surge2_input_train = np.mean(surge2_input_train, axis=1)\n",
    "std_surge2_input_train = np.std(surge2_input_train, axis=1)\n",
    "\n",
    "scaled_surge1_input_train = (surge1_input_train - mean_surge1_input_train[:,None]) / std_surge1_input_train[:,None]\n",
    "scaled_surge2_input_train = (surge2_input_train - mean_surge2_input_train[:,None]) / std_surge2_input_train[:,None]\n",
    "\n",
    "t_surge1_output_train = X_train['t_surge1_output']\n",
    "t_surge2_output_train = X_train['t_surge2_output']\n",
    "\n",
    "# test\n",
    "slp_test = X_test['slp']\n",
    "t_slp_test = X_test['t_slp']\n",
    "\n",
    "t_surge1_input_test = X_test['t_surge1_input']\n",
    "t_surge2_input_test = X_test['t_surge2_input']\n",
    "\n",
    "surge1_input_test = X_test['surge1_input']\n",
    "surge2_input_test = X_test['surge2_input']\n",
    "\n",
    "mean_surge1_input_test = np.mean(surge1_input_test, axis=1)\n",
    "std_surge1_input_test = np.std(surge1_input_test, axis=1)\n",
    "mean_surge2_input_test = np.mean(surge2_input_test, axis=1)\n",
    "std_surge2_input_test = np.std(surge2_input_test, axis=1)\n",
    "\n",
    "scaled_surge1_input_test = (surge1_input_test - mean_surge1_input_test[:,None]) / std_surge1_input_test[:,None]\n",
    "scaled_surge2_input_test = (surge2_input_test - mean_surge2_input_test[:,None]) / std_surge2_input_test[:,None]\n",
    "\n",
    "t_surge1_output_test = X_test['t_surge1_output']\n",
    "t_surge2_output_test = X_test['t_surge2_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to divide the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = Y_train[['surge1_t0', 'surge1_t1', 'surge1_t2', 'surge1_t3', 'surge1_t4', 'surge1_t5', 'surge1_t6', 'surge1_t7', 'surge1_t8', 'surge1_t9']].to_numpy()\n",
    "Y_2 = Y_train[['surge2_t0', 'surge2_t1', 'surge2_t2', 'surge2_t3', 'surge2_t4', 'surge2_t5', 'surge2_t6', 'surge2_t7', 'surge2_t8', 'surge2_t9']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to have a series of pressures the same as the surges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = data_prepare_play(X_train)\n",
    "#test_dataloader2 = data_prepare_play(X_test, train_set = False, surge1 = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the transformer to compute the features from the pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "surge_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = PressureEncorder()\n",
    "device = torch.device('cuda')\n",
    "model1 = model1.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3b6f74753845e9904992af08228281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALESSA~1\\AppData\\Local\\Temp/ipykernel_17248/1416201409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_weighted_losses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ALESSA~1\\AppData\\Local\\Temp/ipykernel_17248/198002562.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mpressure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mViT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpressure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, pixel_values, head_mask, output_attentions, output_hidden_states, interpolate_pos_encoding, return_dict)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0membedding_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolate_pos_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, pixel_values, interpolate_pos_encoding)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolate_pos_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "epochs = 13\n",
    "batch_size=8\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model1.train()\n",
    "    for x1, x2, x3, y in tqdm(train_dataloader, total = len(train_dataloader), leave=False):\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.cuda.FloatTensor)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model1((x1, x2, x3))\n",
    "        loss = custom_weighted_losses(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model1.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        y_preds = []\n",
    "        y_vali = []\n",
    "        #p = 0\n",
    "        for x1, x2, x3, y in tqdm(val_dataloader, total = len(val_dataloader), leave = False):\n",
    "            x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "            x1 = x1.type(torch.cuda.FloatTensor)\n",
    "            x2 = x2.type(torch.cuda.FloatTensor)\n",
    "            x3 = x3.type(torch.cuda.FloatTensor)\n",
    "            y = y.type(torch.cuda.FloatTensor)\n",
    "            pred = model1((x1, x2, x3))\n",
    "            #loss = criterion(pred, y)\n",
    "            #val_loss += loss.item()\n",
    "            #p+=1\n",
    "            y_preds.append(pred.to('cpu'))\n",
    "            y_vali.append(y.to('cpu'))\n",
    "\n",
    "    y_pred = []\n",
    "    y_val = []\n",
    "    for j in y_preds:\n",
    "        for i in j:\n",
    "            y_pred.append(i.numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    for j in y_vali:\n",
    "        for i in j:\n",
    "            y_val.append(i.numpy())\n",
    "    y_val = np.array(y_val)\n",
    "        \n",
    "    a=(y_pred-y_val)**2\n",
    "    b = a*np.array([1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1])\n",
    "    val_loss = b.mean()\n",
    "    #val_loss =val_loss/p\n",
    "    print(f'Epoch {epoch+1}: Validation Loss = {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1.state_dict(), MODEL_PATH + 'model1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = PressureEncorder()\n",
    "model1.load_state_dict(torch.load(MODEL_PATH + 'model1'))\n",
    "model1.eval()\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdbe1b3818a4c9595969326764f7228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.eval()\n",
    "y_preds = []\n",
    "with torch.no_grad():\n",
    "    for x1, x2, x3 in tqdm(test_dataloader1, total = len(test_dataloader1), leave = False):\n",
    "        x1, x2, x3 = x1.to(device), x2.to(device), x3.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        pred = model1((x1, x2, x3))\n",
    "        y_preds.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55f9dea9fc3431f96004622069a7100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.eval()\n",
    "y_preds = []\n",
    "y_vali = []\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for x1, x2, x3, y in tqdm(val_dataloader1, total = len(val_dataloader1), leave = False):\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.cuda.FloatTensor)\n",
    "        pred = model1((x1, x2, x3))\n",
    "        y_preds.append(pred.to('cpu'))\n",
    "        y_vali.append(y.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_val = []\n",
    "\n",
    "for j in y_preds:\n",
    "    for i in j:\n",
    "        y_pred.append(i.numpy())\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "for j in y_vali:\n",
    "    for i in j:\n",
    "        y_val.append(i.numpy())\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=(y_pred-y_val)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a*np.array([1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38195821640475774"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surge_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = PressureEncorder()\n",
    "device = torch.device('cuda')\n",
    "model2 = model2.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 8\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model2.train()\n",
    "    for x1, x2, x3, y in tqdm(train_dataloader2, total = len(train_dataloader2), leave=False):\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        x1 = x1.type(torch.cuda.FloatTensor)\n",
    "        x2 = x2.type(torch.cuda.FloatTensor)\n",
    "        x3 = x3.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.cuda.FloatTensor)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model2((x1, x2, x3))\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model2.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, x3, y in tqdm(val_dataloader2, total = len(val_dataloader2), leave = False):\n",
    "            x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "            x1 = x1.type(torch.cuda.FloatTensor)\n",
    "            x2 = x2.type(torch.cuda.FloatTensor)\n",
    "            x3 = x3.type(torch.cuda.FloatTensor)\n",
    "            y = y.type(torch.cuda.FloatTensor)\n",
    "            pred = model2((x1, x2, x3))\n",
    "            loss = criterion(pred, y)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= (len(val_dataloader2)*batch_size)\n",
    "    print(f'Epoch {epoch+1}: Validation Loss = {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), MODEL_PATH + 'model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.load(MODEL_PATH + 'model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALESSA~1\\AppData\\Local\\Temp/ipykernel_12628/163729991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "model1.eval(test_dataloader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1d83f4d4fbbec24dd5335a3ea8411cfa594cd5b986a6b3006b93e5d6545557f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mallatproj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
