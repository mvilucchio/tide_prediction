{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTFeatureExtractor, ViTModel, ViTConfig, DistilBertModel, DistilBertConfig\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data is loaded and scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/X_train_surge_new.npz')\n",
    "Y_train = pd.read_csv('./data/Y_train_surge.csv')\n",
    "X_test = np.load('./data/X_test_surge_new.npz')\n",
    "\n",
    "# train\n",
    "slp_train = X_train['slp']\n",
    "t_slp_train = X_train['t_slp']\n",
    "\n",
    "t_surge1_input_train = X_train['t_surge1_input']\n",
    "t_surge2_input_train = X_train['t_surge2_input']\n",
    "\n",
    "surge1_input_train = X_train['surge1_input']\n",
    "surge2_input_train = X_train['surge2_input']\n",
    "\n",
    "mean_surge1_input_train = np.mean(surge1_input_train, axis=1)\n",
    "std_surge1_input_train = np.std(surge1_input_train, axis=1)\n",
    "mean_surge2_input_train = np.mean(surge2_input_train, axis=1)\n",
    "std_surge2_input_train = np.std(surge2_input_train, axis=1)\n",
    "\n",
    "scaled_surge1_input_train = (surge1_input_train - mean_surge1_input_train[:,None]) / std_surge1_input_train[:,None]\n",
    "scaled_surge2_input_train = (surge2_input_train - mean_surge2_input_train[:,None]) / std_surge2_input_train[:,None]\n",
    "\n",
    "t_surge1_output_train = X_train['t_surge1_output']\n",
    "t_surge2_output_train = X_train['t_surge2_output']\n",
    "\n",
    "# test\n",
    "slp_test = X_test['slp']\n",
    "t_slp_test = X_test['t_slp']\n",
    "\n",
    "t_surge1_input_test = X_test['t_surge1_input']\n",
    "t_surge2_input_test = X_test['t_surge2_input']\n",
    "\n",
    "surge1_input_test = X_test['surge1_input']\n",
    "surge2_input_test = X_test['surge2_input']\n",
    "\n",
    "mean_surge1_input_test = np.mean(surge1_input_test, axis=1)\n",
    "std_surge1_input_test = np.std(surge1_input_test, axis=1)\n",
    "mean_surge2_input_test = np.mean(surge2_input_test, axis=1)\n",
    "std_surge2_input_test = np.std(surge2_input_test, axis=1)\n",
    "\n",
    "scaled_surge1_input_test = (surge1_input_test - mean_surge1_input_test[:,None]) / std_surge1_input_test[:,None]\n",
    "scaled_surge2_input_test = (surge2_input_test - mean_surge2_input_test[:,None]) / std_surge2_input_test[:,None]\n",
    "\n",
    "t_surge1_output_test = X_test['t_surge1_output']\n",
    "t_surge2_output_test = X_test['t_surge2_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to divide the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = Y_train[['surge1_t0', 'surge1_t1', 'surge1_t2', 'surge1_t3', 'surge1_t4', 'surge1_t5', 'surge1_t6', 'surge1_t7', 'surge1_t8', 'surge1_t9']].to_numpy()\n",
    "Y_2 = Y_train[['surge2_t0', 'surge2_t1', 'surge2_t2', 'surge2_t3', 'surge2_t4', 'surge2_t5', 'surge2_t6', 'surge2_t7', 'surge2_t8', 'surge2_t9']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to have a series of pressures the same as the surges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressures_same_time_1 = np.empty((*(t_surge1_input_train.shape), 41, 41))\n",
    "for i, time_series in enumerate(t_surge1_input_train):\n",
    "    for j, time in enumerate(time_series):\n",
    "        idx = find_nearest(t_slp_train[i,:].flatten(), time)\n",
    "        pressures_same_time_1[i, j, :, :] = slp_train[i, idx, :, :]\n",
    "\n",
    "pressures_same_time_2 = np.empty((*(t_surge2_input_train.shape), 41, 41))\n",
    "for i, time_series in enumerate(t_surge2_input_train):\n",
    "    for j, time in enumerate(time_series):\n",
    "        idx = find_nearest(t_slp_train[i,:].flatten(), time)\n",
    "        pressures_same_time_2[i, j, :, :] = slp_train[i, idx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pressures_same_time_1 = np.mean(pressures_same_time_1, axis=(1,2,3))\n",
    "std_pressures_same_time_1 = np.std(pressures_same_time_1, axis=(1,2,3))\n",
    "mean_pressures_same_time_2 = np.mean(pressures_same_time_2, axis=(1,2,3))\n",
    "std_pressures_same_time_2 = np.std(pressures_same_time_2, axis=(1,2,3))\n",
    "\n",
    "scaled_pressures_same_time_1 = (pressures_same_time_1 - mean_pressures_same_time_1[:,None, None, None]) / std_pressures_same_time_1[:,None, None, None]\n",
    "scaled_pressures_same_time_2 = (pressures_same_time_2 - mean_pressures_same_time_2[:,None, None, None]) / std_pressures_same_time_2[:,None, None, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_rounder(t):\n",
    "    return (t.replace(second=0, microsecond=0, minute=0, hour=t.hour) + timedelta(hours=t.minute//30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_hour(array):\n",
    "    hours_array = np.empty_like(array)\n",
    "    for i, times in enumerate(array):\n",
    "        for j, t in enumerate(times):\n",
    "            if t<0:\n",
    "                tt = (datetime(1970,1,1) + timedelta(seconds=int(t))).timetuple()\n",
    "            else:\n",
    "                tt = (datetime.fromtimestamp(int(t))).timetuple() \n",
    "            hours_array[i][j] = tt.tm_yday * 24 + tt.tm_hour\n",
    "    return hours_array / (366 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_in_year_surge_1_train = time_to_hour(t_surge1_input_train)\n",
    "hours_in_year_surge_2_train = time_to_hour(t_surge2_input_train)\n",
    "hours_in_year_surge_1_test = time_to_hour(t_surge1_input_test)\n",
    "hours_in_year_surge_2_test = time_to_hour(t_surge2_input_test)\n",
    "hours_in_year_surge_1_output_train = time_to_hour(t_surge1_output_train)\n",
    "hours_in_year_surge_2_output_train = time_to_hour(t_surge2_output_train)\n",
    "hours_in_year_slp_train = time_to_hour(t_slp_train)\n",
    "hours_in_year_slp_test = time_to_hour(t_slp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hours_in_year_surge_1_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datalen = len(surge1_input_train)\n",
    "trainlen = int(0.9 * datalen)\n",
    "vallen = datalen - trainlen\n",
    "train_idx, val_idx = torch.utils.data.random_split(np.arange(datalen), [trainlen, vallen])\n",
    "\n",
    "pressure1_train, pressure1_val = pressures_same_time_1[train_idx], pressures_same_time_1[val_idx]\n",
    "surge1_train, surge1_val = surge1_input_train[train_idx], surge1_input_train[val_idx]\n",
    "t_surge1_train, t_surge1_val = hours_in_year_surge_1_train[train_idx], hours_in_year_surge_1_train[val_idx]\n",
    "Y_1_train, Y_1_val = Y_1[train_idx], Y_1[val_idx]\n",
    "\n",
    "train_data = list(zip(pressure1_train, surge1_train, t_surge1_train, Y_1_train))\n",
    "val_data = list(zip(pressure1_val, surge1_val, t_surge1_val, Y_1_val))\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nnn = 100\n",
    "pressures_same_time_1_flatten = pressures_same_time_1.reshape(-1, 1, 41, 41)[:nnn]\n",
    "surge1_input_train_flatten = surge1_input_train.reshape(-1, 1)[:nnn]\n",
    "hours_in_year_surge_1_train_flatten = hours_in_year_surge_1_train.reshape(-1, 1)[:nnn]\n",
    "Y_1_flatten = Y_1.reshape(-1, 1)[:nnn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datalen = len(pressures_same_time_1_flatten)\n",
    "trainlen = int(0.9 * datalen)\n",
    "vallen = datalen - trainlen\n",
    "train_idx, val_idx = torch.utils.data.random_split(np.arange(datalen), [trainlen, vallen])\n",
    "\n",
    "pressure1_train, pressure1_val = pressures_same_time_1_flatten[train_idx], pressures_same_time_1_flatten[val_idx]\n",
    "surge1_train, surge1_val = surge1_input_train_flatten[train_idx], surge1_input_train_flatten[val_idx]\n",
    "t_surge1_train, t_surge1_val = hours_in_year_surge_1_train_flatten[train_idx], hours_in_year_surge_1_train_flatten[val_idx]\n",
    "Y_1_train, Y_1_val = Y_1_flatten[train_idx], Y_1_flatten[val_idx]\n",
    "\n",
    "train_data = list(zip(pressure1_train, surge1_train, t_surge1_train, Y_1_train))\n",
    "val_data = list(zip(pressure1_val, surge1_val, t_surge1_val, Y_1_val))\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader_flatten = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader_flatten = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.linspace(1, 0.1, 10)[np.newaxis]\n",
    "\n",
    "def benchmark_weighted_losses(output, target):\n",
    "    loss = torch.mean(w * (output - target)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the transformer to compute the features from the pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = PressureEncorder()\n",
    "# device = torch.device('cuda')\n",
    "# model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for x1, x2, x3, y in tqdm(train_dataloader_flatten, total = len(train_dataloader), leave=False):\n",
    "        # x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        x1 = x1.type(torch.FloatTensor)\n",
    "        x2 = x2.type(torch.FloatTensor)\n",
    "        x3 = x3.type(torch.FloatTensor)\n",
    "        y = y.type(torch.FloatTensor)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model((x1, x2, x3))\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, x3, y in tqdm(val_dataloader_flatten, total = len(val_dataloader), leave = False):\n",
    "            # x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "            x1 = x1.type(torch.FloatTensor)\n",
    "            x2 = x2.type(torch.FloatTensor)\n",
    "            x3 = x3.type(torch.FloatTensor)\n",
    "            y = y.type(torch.FloatTensor)\n",
    "            pred = model((x1, x2, x3))\n",
    "            loss = criterion(pred, y)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= (len(val_dataloader)*batch_size)\n",
    "    print(f'Epoch {epoch+1}: Validation Loss = {val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnn = -1\n",
    "\n",
    "pressures_same_time_1_flatten = scaled_pressures_same_time_1[:nnn]\n",
    "pressures_same_time_2_flatten = scaled_pressures_same_time_2[:nnn]\n",
    "\n",
    "surge1_input_train_flatten = surge1_input_train[:nnn]\n",
    "surge2_input_train_flatten = surge2_input_train[:nnn]\n",
    "\n",
    "hours_in_year_surge_1_train_flatten = hours_in_year_surge_1_train[:nnn]\n",
    "hours_in_year_surge_2_train_flatten = hours_in_year_surge_2_train[:nnn]\n",
    "\n",
    "Y_1_flatten = Y_1[:nnn]\n",
    "Y_2_flatten = Y_2[:nnn]\n",
    "\n",
    "mean_pressures_same_time_1_flatten = mean_pressures_same_time_1[:nnn]\n",
    "std_pressures_same_time_1_flatten = std_pressures_same_time_1[:nnn]\n",
    "mean_pressures_same_time_2_flatten = mean_pressures_same_time_2[:nnn]\n",
    "std_pressures_same_time_2_flatten = std_pressures_same_time_2[:nnn]\n",
    "\n",
    "mean_surge1_input_train_flatten = mean_surge1_input_train[:nnn]\n",
    "std_surge1_input_train_flatten = std_surge1_input_train[:nnn]\n",
    "mean_surge2_input_train_flatten = mean_surge2_input_train[:nnn]\n",
    "std_surge2_input_train_flatten = std_surge2_input_train[:nnn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = len(pressures_same_time_1_flatten)\n",
    "trainlen = int(0.9 * datalen)\n",
    "vallen = datalen - trainlen\n",
    "train_idx, val_idx = torch.utils.data.random_split(np.arange(datalen), [trainlen, vallen])\n",
    "\n",
    "pressure1_train, pressure1_val = pressures_same_time_1_flatten[train_idx], pressures_same_time_1_flatten[val_idx]\n",
    "surge1_train, surge1_val = surge1_input_train_flatten[train_idx], surge1_input_train_flatten[val_idx]\n",
    "t_surge1_train, t_surge1_val = hours_in_year_surge_1_train_flatten[train_idx], hours_in_year_surge_1_train_flatten[val_idx]\n",
    "Y_1_train, Y_1_val = Y_1_flatten[train_idx], Y_1_flatten[val_idx]\n",
    "\n",
    "pressure2_train, pressure2_val = pressures_same_time_2_flatten[train_idx], pressures_same_time_2_flatten[val_idx]\n",
    "surge2_train, surge2_val = surge2_input_train_flatten[train_idx], surge2_input_train_flatten[val_idx]\n",
    "t_surge2_train, t_surge2_val = hours_in_year_surge_2_train_flatten[train_idx], hours_in_year_surge_2_train_flatten[val_idx]\n",
    "Y_2_train, Y_2_val = Y_2_flatten[train_idx], Y_2_flatten[val_idx]\n",
    "\n",
    "mean_pressures_same_time_1_train, mean_pressures_same_time_1_val = mean_pressures_same_time_1_flatten[train_idx], mean_pressures_same_time_1_flatten[val_idx]\n",
    "std_pressures_same_time_1_train, std_pressures_same_time_1_val = std_pressures_same_time_1_flatten[train_idx], std_pressures_same_time_1_flatten[val_idx]\n",
    "mean_pressures_same_time_2_train, mean_pressures_same_time_2_val = mean_pressures_same_time_2_flatten[train_idx], mean_pressures_same_time_2_flatten[train_idx]\n",
    "std_pressures_same_time_2_train, std_pressures_same_time_2_val = std_pressures_same_time_2_flatten[train_idx], std_pressures_same_time_2_flatten[val_idx]\n",
    "\n",
    "mean_surge1_input_train_train, mean_surge1_input_train_val = mean_surge1_input_train_flatten[train_idx], mean_surge1_input_train_flatten[val_idx]\n",
    "std_surge1_input_train_train, std_surge1_input_train_val = std_surge1_input_train_flatten[train_idx], std_surge1_input_train_flatten[val_idx]\n",
    "mean_surge2_input_train_train, mean_surge2_input_train_val = mean_surge2_input_train_flatten[train_idx], mean_surge2_input_train_flatten[train_idx]\n",
    "std_surge2_input_train_train, std_surge2_input_train_val = std_surge2_input_train_flatten[train_idx], std_surge2_input_train_flatten[val_idx]\n",
    "\n",
    "train_data = list(zip(\n",
    "    pressure1_train, \n",
    "    pressure2_train, \n",
    "    t_surge1_train, t_surge2_train, \n",
    "    surge1_train, surge2_train, \n",
    "    mean_surge1_input_train_train, mean_surge2_input_train_train, \n",
    "    std_surge1_input_train_train, std_surge2_input_train_train,\n",
    "    mean_pressures_same_time_1_train, mean_pressures_same_time_2_train,\n",
    "    std_pressures_same_time_1_train, std_pressures_same_time_2_train,\n",
    "    Y_1_train,\n",
    "    Y_2_train\n",
    "))\n",
    "val_data = list(zip(\n",
    "    pressure1_val, \n",
    "    pressure2_val, \n",
    "    t_surge1_val, t_surge2_val, \n",
    "    surge1_val, surge2_val, \n",
    "    mean_surge1_input_train_val, mean_surge2_input_train_val, \n",
    "    std_surge1_input_train_val, std_surge2_input_train_val,\n",
    "    mean_pressures_same_time_1_val, mean_pressures_same_time_2_val,\n",
    "    std_pressures_same_time_1_val, std_pressures_same_time_2_val,\n",
    "    Y_1_val,\n",
    "    Y_2_val\n",
    "))\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader_small = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader_small = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelseqsimple = models.EncoderSeqVit()\n",
    "device = torch.device('cuda')\n",
    "modelseqsimple = modelseqsimple.to(device)\n",
    "\n",
    "epochs = 10\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(modelseqsimple.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< Updated upstream
       "model_id": "a5d9b77841554ea28bd527e6f56a9c52",
=======
       "model_id": "43cdeb70a6f840f098b7e5e5bd438e51",
>>>>>>> Stashed changes
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
<<<<<<< Updated upstream
     "ename": "RuntimeError",
     "evalue": "Input and hidden tensors are not at the same device, found input tensor at cpu and hidden tensor at cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALESSA~1\\AppData\\Local\\Temp/ipykernel_5420/640780436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelseqsimple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alessandro\\anaconda3\\envs\\mallat\\github_mallat\\tide_prediction\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mc_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         last_x = torch.concat(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 762\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    763\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input and hidden tensors are not at the same device, found input tensor at cpu and hidden tensor at cuda:0"
=======
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALESSA~1\\AppData\\Local\\Temp/ipykernel_15648/2384796452.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelseqsimple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alessandro\\anaconda3\\envs\\mallat\\github_mallat\\tide_prediction\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mc_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         last_x = torch.concat(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mallat\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 762\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    763\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    modelseqsimple.train()\n",
    "    for x in tqdm(train_dataloader_small, total = len(train_dataloader_small), leave=False):\n",
    "        y2 = x[-1].to(device).type(torch.cuda.FloatTensor)\n",
    "        y1 = x[-2].to(device).type(torch.cuda.FloatTensor) # y = x[-1].to(device).type(torch.FloatTensor)\n",
    "        xx = []\n",
    "        for inp in x[:-2]:\n",
    "            xx.append(inp.to(device).type(torch.cuda.FloatTensor))\n",
    "        xx = tuple(xx)\n",
    "        optimizer.zero_grad()\n",
    "        pred = modelseqsimple(xx)\n",
    "        y = torch.concat([y1, y2], dim=1)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    modelseqsimple.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, x3, y in tqdm(val_dataloader_small, total = len(val_dataloader_small), leave = False):\n",
    "            # x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "            y2 = x[-1].to(device).type(torch.cuda.FloatTensor)\n",
    "            y1 = x[-2].to(device).type(torch.cuda.FloatTensor) # y = x[-1].to(device).type(torch.FloatTensor)\n",
    "            xx = []\n",
    "            for inp in x[:-2]:\n",
    "                xx.append(inp.to(device).type(torch.cuda.FloatTensor))\n",
    "            xx = tuple(xx)\n",
    "            pred = modelseqsimple(xx)\n",
    "            y = torch.concat([y1, y2], dim=1)\n",
    "            loss = criterion(pred, y)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= (len(val_dataloader_small))\n",
    "    print(f'Epoch {epoch+1}: Validation Loss = {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8, 9]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2,3,4,5,6,7,8,9]\n",
    "a[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1d83f4d4fbbec24dd5335a3ea8411cfa594cd5b986a6b3006b93e5d6545557f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mallatproj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
